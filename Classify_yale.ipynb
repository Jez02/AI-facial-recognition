{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEb0VDGENcut"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTTlohXBNXfP",
        "outputId": "5f9eb2bb-4c93-4ab3-e28e-349114706274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive # mounts the google drive for a new notebook\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nygdl2G9Nieo",
        "outputId": "a152cb52-d6f4-4356-c54e-8d216b6b4577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified Labels: [11. 12. 12. ... 12. 13. 13.]\n"
          ]
        }
      ],
      "source": [
        "# load the 2 npy files created by the process_yale_images.ipynb\n",
        "from numpy import load\n",
        "import numpy as np\n",
        "path = '/content/drive/My Drive/'\n",
        "# load array\n",
        "y = load(path + 'yaleExtB_target.npy')\n",
        "X = load(path + 'yaleExtB_data.npy')\n",
        "print('Modified Labels:' , y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-6JrSF4ZWW0",
        "outputId": "c9db4952-f1de-4937-80d7-f1a49a547b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_labels : [ 2.  3.  4.  5.  6.  7.  8.  9. 11. 12. 13. 15. 16. 17. 18. 20. 22. 23.\n",
            " 24. 25. 26. 27. 28. 32. 33. 34. 35. 37. 38. 39.]\n"
          ]
        }
      ],
      "source": [
        "unique_labels = np.unique(y)\n",
        "print('unique_labels :' , unique_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b13j8f2VZxyS",
        "outputId": "1cf3148d-b679-4dd5-a192-a11524bd5e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified Labels: [ 8  9  9 ...  9 10 10]\n"
          ]
        }
      ],
      "source": [
        "label_transformations = {\n",
        "    2.: 0, 3.: 1, 4.: 2, 5.: 3, 6.: 4, 7.: 5, 8.: 6, 9.: 7,\n",
        "    11.: 8, 12.: 9, 13.: 10, 15.: 11, 16.: 12, 17.: 13, 18.: 14,\n",
        "    20.: 15, 22.: 16, 23.: 17, 24.: 18, 25.: 19, 26.: 20, 27.: 21,\n",
        "    28.: 22, 32.: 23, 33.: 24, 34.: 25, 35.: 26, 37.: 27, 38.: 28, 39.: 29\n",
        "}\n",
        "\n",
        "y = np.array([label_transformations[label] for label in y])\n",
        "print(\"Modified Labels:\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnnF2kqYfcgQ",
        "outputId": "ef55df32-90b2-4674-9329-530ed1fe8a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_labels : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n"
          ]
        }
      ],
      "source": [
        "unique_labels = np.unique(y)\n",
        "print('unique_labels :' , unique_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Th62dSshOXqa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split,GridSearchCV, RandomizedSearchCV # loads functions from the ML library sklearn\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uz5JnDUOOgEw"
      },
      "outputs": [],
      "source": [
        "# split into a training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "I3HtYdw6Oj6J"
      },
      "outputs": [],
      "source": [
        "# PCA\n",
        "nof_prin_components = 200  # PARAMETER for optimisation in expereiments\n",
        "pca = PCA(n_components=nof_prin_components, whiten=True).fit(X_train)\n",
        "# applies PCA to the train and test images to calculate the principal components\n",
        "X_train_pca = pca.transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltr-qFaqpei6"
      },
      "source": [
        "Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Su6L-tf8xCEi"
      },
      "outputs": [],
      "source": [
        "# Define parameter grid for grid search\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(10,), (180,), (240,), (860,), (920,), (1150,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'batch_size': [16, 128, 256, 512, 1024]\n",
        "}\n",
        "\n",
        "\n",
        "# Create MLPClassifier\n",
        "clf = MLPClassifier(solver='sgd', verbose=True, early_stopping=True)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=3, n_jobs=-1)\n",
        "grid_search.fit(X_train_pca, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best parameters:\", best_params)\n",
        "\n",
        "# Train a neural network with the best parameters\n",
        "best_clf = MLPClassifier(**best_params).fit(X_train_pca, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_clf.predict(X_test_pca)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0fvf8487iNEc"
      },
      "outputs": [],
      "source": [
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print( \"Best parameters:\", best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NrHyKicL3fM9"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "# Assuming best_params and other necessary variables are defined\n",
        "\n",
        "# Record start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Train a neural network with the best parameters\n",
        "best_clf = MLPClassifier(**best_params).fit(X_train_pca, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_clf.predict(X_test_pca)\n",
        "print(classification_report(y_test, y_pred))  # <-- Corrected line\n",
        "\n",
        "# Record end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the running time\n",
        "running_time = end_time - start_time\n",
        "print(f\"Running time: {running_time} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xT3V17415v1f"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_428Fz74pjP2"
      },
      "source": [
        "Random search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nD41SMKs38iD"
      },
      "outputs": [],
      "source": [
        "# Define parameter distributions for random search\n",
        "param_dist = {\n",
        "    'hidden_layer_sizes': [(80,), (530,), (1100,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'batch_size': [32, 128, 256],\n",
        "}\n",
        "\n",
        "\n",
        "# Create MLPClassifier\n",
        "clf = MLPClassifier(solver='sgd', verbose=True, early_stopping=True)\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Perform random search\n",
        "random_search = RandomizedSearchCV(estimator=clf, param_distributions=param_dist, n_iter=10, cv=3, n_jobs=2)\n",
        "random_search.fit(X_train_pca, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best parameters:\", best_params)\n",
        "\n",
        "# Train a neural network with the best parameters\n",
        "best_clf = MLPClassifier(**best_params).fit(X_train_pca, y_train)  # <-- Corrected line\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_clf.predict(X_test_pca)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "22Eot2A2kuEZ"
      },
      "outputs": [],
      "source": [
        "# Record end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the running time\n",
        "running_time = end_time - start_time\n",
        "print(f\"Running time: {running_time} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s1pbSJj62C-2"
      },
      "outputs": [],
      "source": [
        "# Define parameter distributions\n",
        "param_dist = {\n",
        "    'hidden_layer_sizes': [(100,), (200,), (360,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'batch_size': [128, 256, 512],\n",
        "}\n",
        "\n",
        "# Create MLPClassifier\n",
        "clf = MLPClassifier(solver='sgd', verbose=True, early_stopping=True)\n",
        "\n",
        "# Perform random search\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1)\n",
        "random_search.fit(X_train_pca, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best parameters:\", best_params)\n",
        "\n",
        "# Train a neural network with the best parameters\n",
        "best_clf = MLPClassifier(**best_params)\n",
        "best_clf.fit(X_train_pca, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_clf.predict(X_test_pca)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-QYTUWOP2mnk"
      },
      "outputs": [],
      "source": [
        "end_time = time.time()\n",
        "# Calculate and print the running time\n",
        "running_time = end_time - start_time\n",
        "print(f\"Running time: {running_time} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4PyCqp6PwDl"
      },
      "source": [
        "[Documentation of ML sklearn library](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xZ3tZ3u9On_z"
      },
      "outputs": [],
      "source": [
        "# train a neural network\n",
        "nohn = 200 # nof hidden neurons\n",
        "print(\"Fitting the classifier to the training set\")\n",
        "clf = MLPClassifier(hidden_layer_sizes=(nohn,), solver='sgd', activation='tanh', batch_size=256, verbose=True, early_stopping=True).fit(X_train_pca, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GpQlLK8wO-lw"
      },
      "outputs": [],
      "source": [
        "y_pred = clf.predict(X_test_pca) # reoognises the test images\n",
        "print(classification_report(y_test, y_pred)) # the recognition accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jKWzeHCPfG5b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aqGvBqHif0gf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm,annot=True, fmt='d', cmap='Blues' , xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "plt.title('confusion Matrix')\n",
        "plt.xlabel('predicted label')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}